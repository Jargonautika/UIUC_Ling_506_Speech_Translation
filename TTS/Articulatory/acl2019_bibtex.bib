%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Helen Gent at 2019-09-29 18:53:32 -0500 


%% Saved with string encoding Unicode (UTF-8) 



@article{Birkholz2019,
	Author = {Birkholz, Peter and Pape, Daniel},
	Date-Added = {2019-09-27 13:06:24 -0500},
	Date-Modified = {2019-09-27 13:06:43 -0500},
	Doi = {10.1016/j.specom.2019.04.009},
	Journal = {Speech Communication},
	Month = {04},
	Title = {How modeling entrance loss and flow separation in a two-mass model affects the oscillation and synthesis quality},
	Volume = {110},
	Year = {2019},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.specom.2019.04.009},
	Bdsk-File-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAxLi4vLi4vRG93bmxvYWRzLzEtczIuMC1TMDE2NzYzOTMxODMwMTQzMi1tYWluLnBkZk8RAZwAAAAAAZwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAAAAAABCRAAB/////x8xLXMyLjAtUzAxNjc2MzkzMTgjRkZGRkZGRkYucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////AAAAAAAAAAAAAAAAAAIAAgAACiBjdQAAAAAAAAAAAAAAAAAJRG93bmxvYWRzAAACAD0vOlVzZXJzOmhlbGVuZ2VudDpEb3dubG9hZHM6MS1zMi4wLVMwMTY3NjM5MzE4MzAxNDMyLW1haW4ucGRmAAAOAEQAIQAxAC0AcwAyAC4AMAAtAFMAMAAxADYANwA2ADMAOQAzADEAOAAzADAAMQA0ADMAMgAtAG0AYQBpAG4ALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASADtVc2Vycy9oZWxlbmdlbnQvRG93bmxvYWRzLzEtczIuMC1TMDE2NzYzOTMxODMwMTQzMi1tYWluLnBkZgAAEwABLwAAFQACABD//wAAAAgADQAaACQAWAAAAAAAAAIBAAAAAAAAAAUAAAAAAAAAAAAAAAAAAAH4}}

@article{Stone2018,
	Acmid = {3224417},
	Address = {Piscataway, NJ, USA},
	Annote = {This article introduces a new one-dimensional vocal tract model aimed at simplifying articulatory synthesis in the interest of computational economy. The objective evaluation metric they used involved MRI data from a native speaker, so likely would not be something applicable to the constraints of the present problem. Perceptual testing with native listeners indicated that the model was effective.},
	Author = {Stone, Simon and Marxen, Michael and Birkholz, Peter},
	Date-Added = {2019-09-27 13:03:59 -0500},
	Date-Modified = {2019-09-29 18:53:02 -0500},
	Doi = {10.1109/TASLP.2018.2825601},
	Issn = {2329-9290},
	Issue_Date = {August 2018},
	Journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
	Keywords = {Articulatory synthesis},
	Month = aug,
	Number = {8},
	Numpages = {12},
	Pages = {1381--1392},
	Publisher = {IEEE Press},
	Title = {Construction and Evaluation of a Parametric One-Dimensional Vocal Tract Model},
	Url = {https://doi.org/10.1109/TASLP.2018.2825601},
	Volume = {26},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1109/TASLP.2018.2825601},
	Bdsk-File-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAcLi4vLi4vRG93bmxvYWRzLzA4MzM2OTQ0LnBkZk8RAUYAAAAAAUYAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAAAAAABCRAAB/////wwwODMzNjk0NC5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////AAAAAAAAAAAAAAAAAAIAAgAACiBjdQAAAAAAAAAAAAAAAAAJRG93bmxvYWRzAAACACgvOlVzZXJzOmhlbGVuZ2VudDpEb3dubG9hZHM6MDgzMzY5NDQucGRmAA4AGgAMADAAOAAzADMANgA5ADQANAAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAJlVzZXJzL2hlbGVuZ2VudC9Eb3dubG9hZHMvMDgzMzY5NDQucGRmABMAAS8AABUAAgAQ//8AAAAIAA0AGgAkAEMAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAABjQ==}}

@article{Birkholz2015,
	Annote = {This article examines the independent effects of phonation type (voice quality) on emotional speech synthesis. The experiment re-synthesized seven emotions from the Berlin Database of Emotional Speech, and analyzed how changing only phonation type effected the perception of the emotion. Assessment of the samples was native speaker judgement of naturalness, intelligibility, which emotion they heard, and the strength of the emotion. The results found that the listeners found the synthesized speech ``rather natural'' and ``rather intelligible.'' Recognition rates for the synthesized emotions were significantly lower than for natural speech, but higher than chance. Phonation type was nonetheless found to have a significant effect on perceived emotion.},
	Author = {Birkholz, Peter and Martin, Lucia and Willmes, Klaus and Kr{\"o}ger, Bernd and Neuschaefer-Rube, Christiane},
	Date-Added = {2019-09-27 12:56:40 -0500},
	Date-Modified = {2019-09-29 16:16:28 -0500},
	Doi = {10.1121/1.4906836},
	Journal = {The Journal of the Acoustical Society of America},
	Keywords = {Prosody, Emotion, Articulatory synthesis},
	Month = {03},
	Pages = {1503},
	Title = {The contribution of phonation type to the perception of vocal emotions in German: An articulatory synthesis study},
	Volume = {137},
	Year = {2015},
	Bdsk-Url-1 = {https://doi.org/10.1121/1.4906836},
	Bdsk-File-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAdLi4vLi4vRG93bmxvYWRzLzEuNDkwNjgzNi5wZGZPEQFMAAAAAAFMAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAAAAAAAAQkQAAf////8NMS40OTA2ODM2LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/////wAAAAAAAAAAAAAAAAACAAIAAAogY3UAAAAAAAAAAAAAAAAACURvd25sb2FkcwAAAgApLzpVc2VyczpoZWxlbmdlbnQ6RG93bmxvYWRzOjEuNDkwNjgzNi5wZGYAAA4AHAANADEALgA0ADkAMAA2ADgAMwA2AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAnVXNlcnMvaGVsZW5nZW50L0Rvd25sb2Fkcy8xLjQ5MDY4MzYucGRmAAATAAEvAAAVAAIAEP//AAAACAANABoAJABEAAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAAAZQ=}}

@article{Birkholz2017,
	Acmid = {3005481},
	Address = {London, UK, UK},
	Annote = {This paper details an experiment testing the effectiveness of an articulatory TTS system at manipulating so-called ``secondary'' prosodic features such as phonation type, vocal tract length, articulatory precision, and nasality. Their results, judged on native listener perception, indicate that their system is effective in producing noticable differences in these domains.},
	Author = {Birkholz, Peter and Martin, Lucia and Xu, Yi and Scherbaum, Stefan and Neuschaefer-Rube, Christiane},
	Date-Added = {2019-09-27 12:47:29 -0500},
	Date-Modified = {2019-09-29 18:15:05 -0500},
	Doi = {10.1016/j.csl.2016.06.004},
	Issn = {0885-2308},
	Issue_Date = {January 2017},
	Journal = {Comput. Speech Lang.},
	Keywords = {Articulatory synthesis, Feature manipulation, Prosody},
	Month = jan,
	Number = {C},
	Numpages = {12},
	Pages = {116--127},
	Publisher = {Academic Press Ltd.},
	Title = {Manipulation of the Prosodic Features of Vocal Tract Length, Nasality and Articulatory Precision Using Articulatory Synthesis},
	Url = {https://doi.org/10.1016/j.csl.2016.06.004},
	Volume = {41},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.csl.2016.06.004},
	Bdsk-File-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAxLi4vLi4vRG93bmxvYWRzLzEtczIuMC1TMDg4NTIzMDgxNjMwMDA1NS1tYWluLnBkZk8RAZwAAAAAAZwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAAAAAABCRAAB/////x8xLXMyLjAtUzA4ODUyMzA4MTYjRkZGRkZGRkYucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////AAAAAAAAAAAAAAAAAAIAAgAACiBjdQAAAAAAAAAAAAAAAAAJRG93bmxvYWRzAAACAD0vOlVzZXJzOmhlbGVuZ2VudDpEb3dubG9hZHM6MS1zMi4wLVMwODg1MjMwODE2MzAwMDU1LW1haW4ucGRmAAAOAEQAIQAxAC0AcwAyAC4AMAAtAFMAMAA4ADgANQAyADMAMAA4ADEANgAzADAAMAAwADUANQAtAG0AYQBpAG4ALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASADtVc2Vycy9oZWxlbmdlbnQvRG93bmxvYWRzLzEtczIuMC1TMDg4NTIzMDgxNjMwMDA1NS1tYWluLnBkZgAAEwABLwAAFQACABD//wAAAAgADQAaACQAWAAAAAAAAAIBAAAAAAAAAAUAAAAAAAAAAAAAAAAAAAH4}}

@article{Birkholz2013,
	Abstract = {A central challenge for articulatory speech synthesis is the simulation of realistic articulatory movements, which is critical for the generation of highly natural and intelligible speech. This includes modeling coarticulation, i.e., the context-dependent variation of the articulatory and acoustic realization of phonemes, especially of consonants. Here we propose a method to simulate the context-sensitive articulation of consonants in consonant-vowel syllables. To achieve this, the vocal tract target shape of a consonant in the context of a given vowel is derived as the weighted average of three measured and acoustically-optimized reference vocal tract shapes for that consonant in the context of the corner vowels /a/, /i/, and /u/. The weights are determined by mapping the target shape of the given context vowel into the vowel subspace spanned by the corner vowels. The model was applied for the synthesis of consonant-vowel syllables with the consonants /b/, /d/, /g/, /l/, /r/, /m/, /n/ in all combinations with the eight long German vowels. In a perception test, the mean recognition rate for the consonants in the isolated syllables was 82.4%. This demonstrates the potential of the approach for highly intelligible articulatory speech synthesis.},
	Annote = {This article aims to incorporate coarticulation into an articulatory speech synthesis model. The author assumes that the vowels /a/, /i/, and /u/ constitute the extremes of the vowel space and any given vowel as a weighted average of these three - allowing a consonant coarticulated with such a vowel to be affected by this weighted average. Lip shape is also considered. The means of assessment for this model were inteligibility judgements by 20 proficient listeners. The positive results indicate that this method of modeling coarticulation was effective.},
	Author = {Birkholz, Peter},
	Date-Added = {2019-09-27 12:38:19 -0500},
	Date-Modified = {2019-09-29 16:16:17 -0500},
	Doi = {10.1371/journal.pone.0060603},
	Journal = {PLOS ONE},
	Keywords = {Coarticulation, Articulatory synthesis},
	Month = {04},
	Number = {4},
	Pages = {1-17},
	Publisher = {Public Library of Science},
	Title = {Modeling Consonant-Vowel Coarticulation for Articulatory Speech Synthesis},
	Url = {https://doi.org/10.1371/journal.pone.0060603},
	Volume = {8},
	Year = {2013},
	Bdsk-Url-1 = {https://doi.org/10.1371/journal.pone.0060603},
	Bdsk-File-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBGLi4vLi4vRG93bmxvYWRzL01vZGVsaW5nX0NvbnNvbmFudC1Wb3dlbF9Db2FydGljdWxhdGlvbl9mb3JfQXJ0aWN1LnBkZk8RAe4AAAAAAe4AAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAAAAAABCRAAB/////x9Nb2RlbGluZ19Db25zb25hbnQjRkZGRkZGRkYucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////AAAAAAAAAAAAAAAAAAIAAgAACiBjdQAAAAAAAAAAAAAAAAAJRG93bmxvYWRzAAACAFIvOlVzZXJzOmhlbGVuZ2VudDpEb3dubG9hZHM6TW9kZWxpbmdfQ29uc29uYW50LVZvd2VsX0NvYXJ0aWN1bGF0aW9uX2Zvcl9BcnRpY3UucGRmAA4AbgA2AE0AbwBkAGUAbABpAG4AZwBfAEMAbwBuAHMAbwBuAGEAbgB0AC0AVgBvAHcAZQBsAF8AQwBvAGEAcgB0AGkAYwB1AGwAYQB0AGkAbwBuAF8AZgBvAHIAXwBBAHIAdABpAGMAdQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAUFVzZXJzL2hlbGVuZ2VudC9Eb3dubG9hZHMvTW9kZWxpbmdfQ29uc29uYW50LVZvd2VsX0NvYXJ0aWN1bGF0aW9uX2Zvcl9BcnRpY3UucGRmABMAAS8AABUAAgAQ//8AAAAIAA0AGgAkAG0AAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAACXw==}}

@article{Hill2017,
	Author = {Hill, David and Taube-Schock, Craig and Manzara, Leonard},
	Date-Added = {2019-09-26 20:53:02 -0500},
	Date-Modified = {2019-09-27 12:57:02 -0500},
	Doi = {10.1017/cnj.2017.15},
	Journal = {Canadian Journal of Linguistics/Revue canadienne de linguistique},
	Month = {06},
	Pages = {1-40},
	Title = {Low-level articulatory synthesis: A working text-to-speech solution and a linguistic tool},
	Volume = {62},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1017/cnj.2017.15},
	Bdsk-File-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxA0Li4vLi4vRG93bmxvYWRzL2xvdy1sZXZlbC1hcnRpY3VsYXRvcnktc3ludGhlc2lzLnBkZk8RAaYAAAAAAaYAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAAAAAABCRAAB/////x9sb3ctbGV2ZWwtYXJ0aWN1bGEjRkZGRkZGRkYucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////AAAAAAAAAAAAAAAAAAIAAgAACiBjdQAAAAAAAAAAAAAAAAAJRG93bmxvYWRzAAACAEAvOlVzZXJzOmhlbGVuZ2VudDpEb3dubG9hZHM6bG93LWxldmVsLWFydGljdWxhdG9yeS1zeW50aGVzaXMucGRmAA4ASgAkAGwAbwB3AC0AbABlAHYAZQBsAC0AYQByAHQAaQBjAHUAbABhAHQAbwByAHkALQBzAHkAbgB0AGgAZQBzAGkAcwAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAPlVzZXJzL2hlbGVuZ2VudC9Eb3dubG9hZHMvbG93LWxldmVsLWFydGljdWxhdG9yeS1zeW50aGVzaXMucGRmABMAAS8AABUAAgAQ//8AAAAIAA0AGgAkAFsAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAACBQ==}}

@inproceedings{2016Bangla,
	Address = {Portoro{\v z}, Slovenia},
	Annote = {This article presents a bootstrapped TTS system for Bangla using crowd-sourced data from ordinary speakers. Text normalization is bootstrapped from Hindi as it is related and higher resource, then an acoustic model is built using Long Short-Term Memory Recurrent Neural Network and Hidden Markov Model approaches. This is concatenative synthesis, so not directly applicable to research on articulatory synthesis. The front-end bootstrapping could be useful if there were a higher resource language related to Yupik, but that may not be the case. Synthesized speech was evaluated by Mean Opinion Score testing, which does require native speaker judgement.},
	Author = {Alexander Gutkin and Linne Ha and Martin Jansche and Knot Pipatsrisawat and Richard Sproa},
	Booktitle = {10th edition of the Language Resources and Evaluation Conference, 23-28 May 2016},
	Date-Added = {2019-09-26 20:16:32 -0500},
	Date-Modified = {2019-09-29 16:15:22 -0500},
	Keywords = {Low-Resource Languages, Concatenative Synthesis},
	Pages = {2005-2010},
	Title = {TTS for Low Resource Languages: A Bangla Synthesizer},
	Year = {2016},
	Bdsk-File-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAdLi4vLi4vRG93bmxvYWRzLzI4Nl9QYXBlci5wZGZPEQFMAAAAAAFMAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAAAAAAAAQkQAAf////8NMjg2X1BhcGVyLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/////wAAAAAAAAAAAAAAAAACAAIAAAogY3UAAAAAAAAAAAAAAAAACURvd25sb2FkcwAAAgApLzpVc2VyczpoZWxlbmdlbnQ6RG93bmxvYWRzOjI4Nl9QYXBlci5wZGYAAA4AHAANADIAOAA2AF8AUABhAHAAZQByAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAnVXNlcnMvaGVsZW5nZW50L0Rvd25sb2Fkcy8yODZfUGFwZXIucGRmAAATAAEvAAAVAAIAEP//AAAACAANABoAJABEAAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAAAZQ=}}

@inproceedings{Chasaide2015,
	Annote = {This article discusses the function of TTS systems in preserving endangered languages. Irish, in this case. The authors argue that - in the area of letter-to-sound rules - currently popular statistical approaches to TTS are less appropriate for the problem than a rule-based system as this allows the system to be gradually expanded and improved to handle different dialects. The system itself appears to be concatenative, however, so not necessarily applicable to research on articulatory synthesis.},
	Author = {Chasaide, Ailbhe and N{\'\i} Chiar{\'a}in, Neasa and Berthelsen, Harald and Wendler, Christoph and Murphy, Andy},
	Date-Added = {2019-09-25 22:45:47 -0500},
	Date-Modified = {2019-09-29 16:03:57 -0500},
	Keywords = {Endangered Languages, Concatenative Synthesis},
	Month = {08},
	Title = {SPEECH TECHNOLOGY AS DOCUMENTATION FOR ENDANGERED LANGUAGE PRESERVATION: THE CASE OF IRISH},
	Year = {2015},
	Bdsk-File-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAdLi4vLi4vRG93bmxvYWRzL0lDUEhTMTAzNy5wZGZPEQFMAAAAAAFMAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAAAAAAAAQkQAAf////8NSUNQSFMxMDM3LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/////wAAAAAAAAAAAAAAAAACAAIAAAogY3UAAAAAAAAAAAAAAAAACURvd25sb2FkcwAAAgApLzpVc2VyczpoZWxlbmdlbnQ6RG93bmxvYWRzOklDUEhTMTAzNy5wZGYAAA4AHAANAEkAQwBQAEgAUwAxADAAMwA3AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAnVXNlcnMvaGVsZW5nZW50L0Rvd25sb2Fkcy9JQ1BIUzEwMzcucGRmAAATAAEvAAAVAAIAEP//AAAACAANABoAJABEAAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAAAZQ=}}

@article{Betal2019,
	Author = {Birkholz, Peter and Gabriel, Falk and K{\"u}rbis, Steffen and Echternach, Matthias},
	Date-Added = {2019-09-25 22:37:58 -0500},
	Date-Modified = {2019-09-25 22:39:48 -0500},
	Doi = {10.1121/1.5116137},
	Journal = {The Journal of the Acoustical Society of America},
	Month = {07},
	Pages = {223-232},
	Title = {How the peak glottal area affects linear predictive coding-based formant estimates of vowels},
	Volume = {146},
	Year = {2019},
	Bdsk-Url-1 = {https://doi.org/10.1121/1.5116137},
	Bdsk-File-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAoLi4vLi4vRG93bmxvYWRzL2Jpcmtob2x6LTIwMTktamFzYS0xLnBkZk8RAXYAAAAAAXYAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAAAAAABCRAAB/////xhiaXJraG9sei0yMDE5LWphc2EtMS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////AAAAAAAAAAAAAAAAAAIAAgAACiBjdQAAAAAAAAAAAAAAAAAJRG93bmxvYWRzAAACADQvOlVzZXJzOmhlbGVuZ2VudDpEb3dubG9hZHM6Ymlya2hvbHotMjAxOS1qYXNhLTEucGRmAA4AMgAYAGIAaQByAGsAaABvAGwAegAtADIAMAAxADkALQBqAGEAcwBhAC0AMQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAMlVzZXJzL2hlbGVuZ2VudC9Eb3dubG9hZHMvYmlya2hvbHotMjAxOS1qYXNhLTEucGRmABMAAS8AABUAAgAQ//8AAAAIAA0AGgAkAE8AAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAByQ==}}

@article{SurveyTTS,
	Annote = {A short, basic overview of the variety of speech synthesis methods.},
	Author = {Siddhi, Desai and M., Jashin and Bhavik, Desai},
	Date-Added = {2019-09-25 16:29:16 -0500},
	Date-Modified = {2019-09-29 18:15:59 -0500},
	Doi = {10.5120/ijca2017913891},
	Journal = {International Journal of Computer Applications},
	Keywords = {Overview},
	Month = {05},
	Pages = {26-30},
	Title = {Survey on Various Methods of Text to Speech Synthesis},
	Volume = {165},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.5120/ijca2017913891},
	Bdsk-File-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxA4Li4vLi4vRG93bmxvYWRzL2Q5NmFhNGRmOTIxMTYzYTFhZmYzZTJjYjkxOGMwMjFiNWY3NS5wZGZPEQG2AAAAAAG2AAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAAAAAAAAQkQAAf////8fZDk2YWE0ZGY5MjExNjNhMWFmI0ZGRkZGRkZGLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/////wAAAAAAAAAAAAAAAAACAAIAAAogY3UAAAAAAAAAAAAAAAAACURvd25sb2FkcwAAAgBELzpVc2VyczpoZWxlbmdlbnQ6RG93bmxvYWRzOmQ5NmFhNGRmOTIxMTYzYTFhZmYzZTJjYjkxOGMwMjFiNWY3NS5wZGYADgBSACgAZAA5ADYAYQBhADQAZABmADkAMgAxADEANgAzAGEAMQBhAGYAZgAzAGUAMgBjAGIAOQAxADgAYwAwADIAMQBiADUAZgA3ADUALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAEJVc2Vycy9oZWxlbmdlbnQvRG93bmxvYWRzL2Q5NmFhNGRmOTIxMTYzYTFhZmYzZTJjYjkxOGMwMjFiNWY3NS5wZGYAEwABLwAAFQACABD//wAAAAgADQAaACQAXwAAAAAAAAIBAAAAAAAAAAUAAAAAAAAAAAAAAAAAAAIZ}}

@inproceedings{KB2009,
	Abstract = {Articulatory synthesis of speech and singing aims for modeling the production process of speech and singing as human-like or natural as possible. The state of the art is described for all modules of articulatory synthesis systems, i.e. vocal tract models, acoustic models, glottis models, noise source models, and control models generating articulator movements and phonatory control information. While a lot of knowledge is available for the production and for the high quality acoustic realization of static spoken and sung sounds it is suggested to improve the quality of control models especially for the generation of articulatory movements. Thus the main problem which should be addressed for improving articulatory synthesis over the next years is the development of high quality control concepts. It is suggested to use action based control concepts and to gather control knowledge by imitating natural speech acquisition and singing acquisition scenarios. It is emphasized that teacher-learner interaction and production, perception, and compre hension of auditory as well as of visual and somatosensory infor mation (multi modal information) should be included in the acquisition (i.e. training or learning) procedures.},
	Address = {Berlin, Heidelberg},
	Annote = {This is an overview of the state of the art in articulatory speech synthesis as of 2009. It identifies the primary issue of articulator synthesis going forward as the challenge of generating natural vocal tract movements for control modeling. The authors argue that a solution to this problem could lie in training articulatory TTS systems with the ability to perceive and comprehend multimodal input so that they can learn like human speakers or singers.},
	Author = {Kr{\"o}ger, Bernd J. and Birkholz, Peter},
	Booktitle = {Multimodal Signals: Cognitive and Algorithmic Issues},
	Date-Modified = {2019-09-29 16:16:05 -0500},
	Editor = {Esposito, Anna and Hussain, Amir and Marinaro, Maria and Martone, Raffaele},
	Isbn = {978-3-642-00525-1},
	Keywords = {Overview, Articulatory synthesis},
	Pages = {306--319},
	Publisher = {Springer Berlin Heidelberg},
	Title = {Articulatory Synthesis of Speech and Singing: State of the Art and Suggestions for Future Research},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhbxBOAC4ALgAvAC4ALgAvAEQAbwB3AG4AbABvAGEAZABzAC8ASwByAPYAZwBlAHIALQBCAGkAcgBrAGgAbwBsAHoAMgAwADAAOQBfAEMAaABhAHAAdABlAHIAXwBBAHIAdABpAGMAdQBsAGEAdABvAHIAeQBTAHkAbgB0AGgAZQBzAGkAcwBPAGYAUwBwAGUAZQBjAGgAQQAuAHAAZABmTxECEgAAAAACEgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAAAAAAEJEAAH/////H0tymmdlci1CaXJraG9sejIwMCNGRkZGRkZGRi5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP////8AAAAAAAAAAAAAAAAAAgACAAAKIGN1AAAAAAAAAAAAAAAAAAlEb3dubG9hZHMAAAIAWy86VXNlcnM6aGVsZW5nZW50OkRvd25sb2FkczpLcsO2Z2VyLUJpcmtob2x6MjAwOV9DaGFwdGVyX0FydGljdWxhdG9yeVN5bnRoZXNpc09mU3BlZWNoQS5wZGYAAA4AfgA+AEsAcgD2AGcAZQByAC0AQgBpAHIAawBoAG8AbAB6ADIAMAAwADkAXwBDAGgAYQBwAHQAZQByAF8AQQByAHQAaQBjAHUAbABhAHQAbwByAHkAUwB5AG4AdABoAGUAcwBpAHMATwBmAFMAcABlAGUAYwBoAEEALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAFlVc2Vycy9oZWxlbmdlbnQvRG93bmxvYWRzL0tyw7ZnZXItQmlya2hvbHoyMDA5X0NoYXB0ZXJfQXJ0aWN1bGF0b3J5U3ludGhlc2lzT2ZTcGVlY2hBLnBkZgAAEwABLwAAFQACABD//wAAAAgADQAaACQAwwAAAAAAAAIBAAAAAAAAAAUAAAAAAAAAAAAAAAAAAALZ}}

@comment{BibDesk Static Groups{
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<array>
	<dict>
		<key>group name</key>
		<string>Actually Useful</string>
		<key>keys</key>
		<string>Hill2017,KB2009,Birkholz2013,Birkholz2017</string>
	</dict>
</array>
</plist>
}}
