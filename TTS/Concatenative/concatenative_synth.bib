%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%55%%%%%%
% Text to Speech Synthesis for Low-Resource Languages
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{bansal2018pre,
  title={Pre-training on high-resource speech recognition improves low-resource speech-to-text translation},
  author={Bansal, Sameer and Kamper, Herman and Livescu, Karen and Lopez, Adam and Goldwater, Sharon},
  journal={arXiv preprint arXiv:1809.01431},
  year={2018}
}

@article{bansal2018low,
  title={Low-resource speech-to-text translation},
  author={Bansal, Sameer and Kamper, Herman and Livescu, Karen and Lopez, Adam and Goldwater, Sharon},
  journal={arXiv preprint arXiv:1803.09164},
  year={2018}
}

@inproceedings{post2013improved,
  title={Improved speech-to-text translation with the Fisher and Callhome Spanish--English speech translation corpus},
  author={Post, Matt and Kumar, Gaurav and Lopez, Adam and Karakos, Damianos and Callison-Burch, Chris and Khudanpur, Sanjeev},
  booktitle={Proc. IWSLT},
  year={2013}
}

%How to fine-tune this large model?
@article{wang2017tacotron,
  title={Tacotron: Towards end-to-end speech synthesis},
  author={Wang, Yuxuan and Skerry-Ryan, RJ and Stanton, Daisy and Wu, Yonghui and Weiss, Ron J and Jaitly, Navdeep and Yang, Zongheng and Xiao, Ying and Chen, Zhifeng and Bengio, Samy and others},
  journal={arXiv preprint arXiv:1703.10135},
  year={2017}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%55%%%%%
%GENERAL
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{anastasopoulos2017case,
  title={A case study on using speech-to-translation alignments for language documentation},
  author={Anastasopoulos, Antonios and Chiang, David},
  journal={arXiv preprint arXiv:1702.04372},
  year={2017}
}

@inproceedings{povey2011kaldi,
  title={The Kaldi speech recognition toolkit},
  author={Povey, Daniel and Ghoshal, Arnab and Boulianne, Gilles and Burget, Lukas and Glembek, Ondrej and Goel, Nagendra and Hannemann, Mirko and Motlicek, Petr and Qian, Yanmin and Schwarz, Petr and others},
  booktitle={IEEE 2011 workshop on automatic speech recognition and understanding},
  number={CONF},
  year={2011},
  organization={IEEE Signal Processing Society}
}

@inproceedings{tokui2015chainer,
  title={Chainer: a next-generation open source framework for deep learning},
  author={Tokui, Seiya and Oono, Kenta and Hido, Shohei and Clayton, Justin},
  booktitle={Proceedings of workshop on machine learning systems (LearningSys) in the twenty-ninth annual conference on neural information processing systems (NIPS)},
  volume={5},
  pages={1--6},
  year={2015}
}

% Is there a way to do a series of experiments where Helen does articulatory and I concatenative?
@article{khan2016concatenative,
  title={Concatenative speech synthesis: A Review},
  author={Khan, Rubeena A and Chitode, JS},
  journal={International Journal of Computer Applications},
  volume={136},
  number={3},
  pages={6},
  year={2016},
  publisher={Foundation of Computer Science}
}

@article{siddhi2017survey,
  title={Survey on various methods of text to speech synthesis},
  author={Siddhi, Desai and Verghese, Jashin M and Bhavik, Desai},
  journal={International Journal of Computer Applications},
  volume={165},
  number={6},
  pages={26--30},
  year={2017},
  publisher={Foundation of Computer Science}
}
